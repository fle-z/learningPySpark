{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n",
      "|gid|      score|\n",
      "+---+-----------+\n",
      "| a1|90 80 79 80|\n",
      "| a2|79 89 45 60|\n",
      "| a3|57 56 89 75|\n",
      "+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"dataframe_split\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "df = spark.read.csv('hdfs://master:9000/dataset/dataframe_split.csv', inferSchema=True, header=True)\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------------+\n",
      "|gid|      score|               s|\n",
      "+---+-----------+----------------+\n",
      "| a1|90 80 79 80|[90, 80, 79, 80]|\n",
      "| a2|79 89 45 60|[79, 89, 45, 60]|\n",
      "| a3|57 56 89 75|[57, 56, 89, 75]|\n",
      "+---+-----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, explode, concat, concat_ws\n",
    "df_split = df.withColumn(\"s\", split(df['score'], \" \"))\n",
    "df_split.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zipWithIndex:给每个元素生成一个索引\n",
    "#### 排序首先基于分区索引，然后是每个分区内的项目顺序．因此，第一个分区中的第一个item索引为０，最后一个分区中的最后一个item的索引最大．当RDD包含多个分区时此方法需要触发spark作业．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 0), ('b', 1), ('c', 2), ('d', 3)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(['a', 'b', 'c', 'd'], 3).zipWithIndex().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将一列分割成多列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新增列的个数 4\n",
      "列名： [('score_0', 0), ('score_1', 1), ('score_2', 2), ('score_3', 3)]\n",
      "+---+-----------+----------------+-------+-------+-------+-------+\n",
      "|gid|      score|               s|score_0|score_1|score_2|score_3|\n",
      "+---+-----------+----------------+-------+-------+-------+-------+\n",
      "| a1|90 80 79 80|[90, 80, 79, 80]|     90|     80|     79|     80|\n",
      "| a2|79 89 45 60|[79, 89, 45, 60]|     79|     89|     45|     60|\n",
      "| a3|57 56 89 75|[57, 56, 89, 75]|     57|     56|     89|     75|\n",
      "+---+-----------+----------------+-------+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_row = df.first()\n",
    "numAttrs = len(first_row['score'].split(\" \"))\n",
    "print(\"新增列的个数\", numAttrs)\n",
    "attrs = sc.parallelize([\"score_\" + str(i) for i in range(numAttrs)]).zipWithIndex().collect()\n",
    "print(\"列名：\", attrs)\n",
    "for name, index in attrs:\n",
    "    df_split = df_split.withColumn(name, df_split['s'].getItem(index))\n",
    "df_split.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+---+\n",
      "|gid|      score|  e|\n",
      "+---+-----------+---+\n",
      "| a1|90 80 79 80| 90|\n",
      "| a1|90 80 79 80| 80|\n",
      "| a1|90 80 79 80| 79|\n",
      "| a1|90 80 79 80| 80|\n",
      "| a2|79 89 45 60| 79|\n",
      "| a2|79 89 45 60| 89|\n",
      "| a2|79 89 45 60| 45|\n",
      "| a2|79 89 45 60| 60|\n",
      "| a3|57 56 89 75| 57|\n",
      "| a3|57 56 89 75| 56|\n",
      "| a3|57 56 89 75| 89|\n",
      "| a3|57 56 89 75| 75|\n",
      "+---+-----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_explode = df.withColumn(\"e\", explode(split(df['score'], \" \")))\n",
    "df_explode.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------------+-------+-------+-------+-------+------------+\n",
      "|gid|      score|               s|score_0|score_1|score_2|score_3|score_concat|\n",
      "+---+-----------+----------------+-------+-------+-------+-------+------------+\n",
      "| a1|90 80 79 80|[90, 80, 79, 80]|     90|     80|     79|     80|    90807980|\n",
      "| a2|79 89 45 60|[79, 89, 45, 60]|     79|     89|     45|     60|    79894560|\n",
      "| a3|57 56 89 75|[57, 56, 89, 75]|     57|     56|     89|     75|    57568975|\n",
      "+---+-----------+----------------+-------+-------+-------+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_concat = df_split.withColumn(\"score_concat\", concat(df_split['score_0'], \\\n",
    "                                                       df_split['score_1'], df_split['score_2'], df_split['score_3']))\n",
    "df_concat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cancat_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------------+-------+-------+-------+-------+------------+\n",
      "|gid|      score|               s|score_0|score_1|score_2|score_3|score_concat|\n",
      "+---+-----------+----------------+-------+-------+-------+-------+------------+\n",
      "| a1|90 80 79 80|[90, 80, 79, 80]|     90|     80|     79|     80| 90-80-79-80|\n",
      "| a2|79 89 45 60|[79, 89, 45, 60]|     79|     89|     45|     60| 79-89-45-60|\n",
      "| a3|57 56 89 75|[57, 56, 89, 75]|     57|     56|     89|     75| 57-56-89-75|\n",
      "+---+-----------+----------------+-------+-------+-------+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ws = df_split.withColumn(\"score_concat\", concat_ws('-', df_split['score_0'], \\\n",
    "                                                       df_split['score_1'], df_split['score_2'], df_split['score_3']))\n",
    "df_ws.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pivot: 旋转当前[[dataframe]]列并执行指定的聚合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+---+---+----+----+\n",
      "|userID| 20|100|399|1401|1608|\n",
      "+------+---+---+---+----+----+\n",
      "|    18| -1|  3|  1|   3|  -1|\n",
      "|    15|  4| -1|  2|   5|   4|\n",
      "+------+---+---+---+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DataFrame 数据格式:每个用户对每部电影的评分 userID 用户ID,movieID 电影ID,rating评分\n",
    "df=spark.sparkContext.parallelize([[15,399,2], \\\n",
    "                                   [15,1401,5], \\\n",
    "                                   [15,1608,4], \\\n",
    "                                   [15,20,4], \\\n",
    "                                   [18,100,3], \\\n",
    "                                   [18,1401,3], \\\n",
    "                                   [18,399,1]])\\\n",
    "                    .toDF([\"userID\",\"movieID\",\"rating\"])\n",
    "#pivot 多行转多列\n",
    "resultDF = df.groupBy(\"userID\").pivot(\"movieID\").sum(\"rating\").na.fill(-1)\n",
    "#结果\n",
    "resultDF.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
