{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "try:\n",
    "    sc.stop() #停止以前的SparkContext，要不然下面创建工作会失败A\n",
    "except:\n",
    "    pass\n",
    "sc = SparkContext('local', 'movieLens_cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取电影的题材标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unknown|0', 'Action|1', 'Adventure|2', 'Animation|3', \"Children's|4\"]\n"
     ]
    }
   ],
   "source": [
    "genres = sc.textFile('hdfs://master:9000/movieLens/ml-100k/u.genre')\n",
    "print(genres.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**为电影题材编码**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "构造出电影题材的编码字典： {'0': 'unknown', '14': 'Romance', '9': 'Fantasy', '2': 'Adventure', '17': 'War', '15': 'Sci-Fi', '4': \"Children's\", '10': 'Film-Noir', '8': 'Drama', '6': 'Crime', '16': 'Thriller', '3': 'Animation', '5': 'Comedy', '18': 'Western', '1': 'Action', '11': 'Horror', '13': 'Mystery', '12': 'Musical', '7': 'Documentary'}\n"
     ]
    }
   ],
   "source": [
    "genre_map = genres.filter(lambda x: len(x) > 0).\\\n",
    "                map(lambda line: line.split('|')).\\\n",
    "                map(lambda x: (x[1], x[0])).collectAsMap()\n",
    "print('构造出电影题材的编码字典：', genre_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**提取电影的title和genres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "电影数据集的第一条数据： 1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0\n",
      "电影标题： ['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', 'Get Shorty (1995)', 'Copycat (1995)']\n",
      "电影的题材：\n",
      "[['0', '0', '0', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], ['0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0'], ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0'], ['0', '1', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], ['0', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0']]\n"
     ]
    }
   ],
   "source": [
    "movies = sc.textFile('hdfs://master:9000/movieLens/ml-100k/u.item')\n",
    "print('电影数据集的第一条数据：', movies.first())\n",
    "#查看电影的标题\n",
    "movies_title = movies.map(lambda x: x.split('|')).map(lambda x: x[1])\n",
    "print('电影标题：', movies_title.take(5))\n",
    "#查看电影的题材，0表示不属于该题材，1表示属于该题材\n",
    "movies_genre = movies.map(lambda x: x.split('|')).map(lambda x: x[5:])\n",
    "print('电影的题材：')\n",
    "print(movies_genre.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前五部电影的标题和相应的题材类型： [(1, \"Toy Story (1995),Animation,Children's,Comedy\"), (2, 'GoldenEye (1995),Action,Adventure,Thriller'), (3, 'Four Rooms (1995),Thriller'), (4, 'Get Shorty (1995),Action,Comedy,Drama'), (5, 'Copycat (1995),Crime,Drama,Thriller')]\n"
     ]
    }
   ],
   "source": [
    "def getTitleAndGenreName(rdd):\n",
    "    genres = rdd[5:]\n",
    "    genres_assigned = zip(genres, range(len(genres)))\n",
    "    index = [] #存储题材特征值为1的特征索引号\n",
    "    for genre, idx in genres_assigned:\n",
    "        if genre == '1':\n",
    "            index.append(idx)\n",
    "    index_val = [genre_map[str(i)] for i in index] #根据编码字典找出索引的相应题材名\n",
    "    index_val_str = ','.join(index_val)\n",
    "    \n",
    "    return (int(rdd[0]), rdd[1] + ',' + index_val_str)\n",
    "\n",
    "titles_and_genres = movies.map(lambda x: x.split('|')).map(lambda x: getTitleAndGenreName(x))\n",
    "print('前五部电影的标题和相应的题材类型：', titles_and_genres.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练推荐模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交替最小二乘法（ALS）\n",
    "ALS 的核心就是下面这个假设：打分矩阵A是近似低秩的。换句话说，一个m×n的打分矩阵**A**可以用两个小矩阵U(m×k)和V(n×k)的乘积来近似。这样我们就把整个系统的自由度从一下O(mn)降到了O((m+n)×k)  \n",
    "世上万千事物，人们的喜好各不相同。但描述一个人的喜好经常是在一个抽象的低维空间上进行的，并不需要把其喜欢的事物一一列出。  \n",
    "举个例子，我喜欢看略带黑色幽默的警匪电影，那么大家根据这个描述就知道我大概会喜欢昆汀的《低俗小说》、《落水狗》和韦家辉的《一个字头的诞生》。这些电影都符合我对自己喜好的描述，也就是说他们在这个抽象的低维空间的投影和我的喜好相似。  \n",
    "再抽象一些，把人们的喜好和电影的特征都投到这个低维空间，一个人的喜好映射到了一个低维向量，一个电影的特征变成了纬度相同的向量，那么这个人和这个电影的相似度就可以表述成这两个向量之间的内积。  \n",
    "我们把打分理解成相似度，那么“打分矩阵A(m*n)”就可以由“用户喜好特征矩阵U(m*k)”和“产品特征矩阵V(n*k)”的乘积来近似了。  \n",
    "具体过程查看[矩阵分解模型（1）：ALS学习算法](https://blog.csdn.net/oucpowerman/article/details/49847979)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在可以开始训练模型了,所需的其他参数有以下几个。\n",
    "* rank:对应ALS模型中的因子个数,也就是在低阶近似矩阵中的隐含特征个数。因子个数一般越多越好。但它也会直接影响模型训练和保存时所需的内存开销,尤其是在用户和物品很多的时候。因此实践中该参数常作为训练效果与系统开销之间的调节参数。通常,其合理取值为10到200。\n",
    "* iterations:对应运行时的迭代次数。ALS能确保每次迭代都能降低评级矩阵的重建误差,但一般经少数次迭代后ALS模型便已能收敛为一个比较合理的好模型。这样,大部分情况下都没必要迭代太多次(10次左右一般就挺好)。\n",
    "* lambda:该参数控制模型的正则化过程,从而控制模型的过拟合情况。其值越高,正则化越严厉。该参数的赋值与实际数据的大小、特征和稀疏程度有关。和其他的机器学习模型一样,正则参数应该通过用非样本的测试数据进行交叉验证来调整。  \n",
    "\n",
    "作为示例,这里将使用的rank、iterations和lambda参数的值分别为50、10和0.01:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw data sample: [['196', '242', '3', '881250949'], ['186', '302', '3', '891717742'], ['22', '377', '1', '878887116']]\n",
      "rating data sample: [Rating(user=196, product=242, rating=3.0), Rating(user=186, product=302, rating=3.0), Rating(user=22, product=377, rating=1.0)]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "from pyspark.mllib.recommendation import Rating\n",
    "\n",
    "raw_data = sc.textFile('hdfs://master:9000/movieLens/ml-100k/u.data')\n",
    "#数据集u.data中四个字段分别表示用户ID、电影ID、评分、时间戳\n",
    "print('raw data sample:', raw_data.map(lambda x: x.split('\\t')).take(3))\n",
    "\n",
    "raw_rating = raw_data.map(lambda x: x.split('\\t')[:3])\n",
    "ratings = raw_rating.map(lambda x: Rating(x[0], x[1], x[2]))\n",
    "ratings.cache()\n",
    "print('rating data sample:', ratings.take(3))\n",
    "\n",
    "#训练推荐模型\n",
    "als_model = ALS.train(ratings, 50, 5, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "movie_factors = als_model.productFeatures().map(lambda x: (x[0], Vectors.dense(x[1])))\n",
    "movie_vectors = movie_factors.map(lambda x: x[1])\n",
    "\n",
    "user_factors = als_model.userFeatures().map(lambda x: (x[0], Vectors.dense(x[1])))\n",
    "user_vectors = user_factors.map(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 归一化\n",
    "在训练聚类模型之前，有必要观察一下输入数据的相关因素特征向量的分布，这可以告诉我们是否需要对训练数据进行归一化  \n",
    "从下面的结果来看，没有发现特别立群的点会影响聚类结果，因此也就没必要进行归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method JavaModelWrapper.__del__ of <pyspark.mllib.stat._statistics.MultivariateStatisticalSummary object at 0x7fc32e8686d8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/pyspark/mllib/common.py\", line 142, in __del__\n",
      "    self._sc._gateway.detach(self._java_model)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1870, in detach\n",
      "AttributeError: 'RDD' object has no attribute '_detach'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie factors mean: [ -2.46042605e-01   4.09215370e-01   1.71205918e-01  -3.99813389e-02\n",
      "   4.45088787e-01   2.57521659e-01  -3.37851754e-01   1.94622614e-01\n",
      "  -8.46795980e-02   3.89513004e-02   1.82929406e-01   3.34531888e-01\n",
      "  -1.26887030e-01  -1.76767938e-01   1.12459881e-01  -1.18506279e-01\n",
      "   3.36070223e-02  -1.85314937e-01  -3.09632505e-01  -1.32173863e-01\n",
      "   3.65567397e-04   9.90960281e-02   4.80696659e-02  -1.92687931e-01\n",
      "   9.01135470e-02  -1.40105695e-01   1.69925708e-01   7.14769749e-02\n",
      "  -2.02924173e-01   7.92776238e-02  -1.70273464e-01  -9.42535695e-02\n",
      "  -3.57966176e-01   2.97810137e-01  -1.99743315e-01  -1.16254592e-01\n",
      "   1.86592883e-01   2.46867168e-01  -1.36812178e-01   1.54292215e-01\n",
      "   5.67643408e-02   3.49779028e-02   1.36715592e-01  -1.74479573e-01\n",
      "   1.37425726e-01  -2.49777473e-01   2.44814970e-01   2.06469067e-01\n",
      "   1.20410172e-01  -6.83830333e-02]\n",
      "Movie factors variance: [-0.40489061  0.60710787  0.27739984 -0.00444145  0.62699867  0.37975445\n",
      " -0.48969531  0.27382579 -0.09089343  0.07567752  0.23006341  0.48762949\n",
      " -0.19377284 -0.24582141  0.20567095 -0.16222921  0.01669201 -0.2840787\n",
      " -0.41845599 -0.22397827 -0.03120276  0.15703829  0.08615412 -0.27170784\n",
      "  0.124315   -0.13345119  0.20853923  0.07387022 -0.30600857  0.12557602\n",
      " -0.24507927 -0.16322722 -0.52412399  0.50803819 -0.33848482 -0.13235721\n",
      "  0.29782255  0.37875076 -0.22077726  0.24238565  0.05848095  0.07936895\n",
      "  0.21921768 -0.2737873   0.17204318 -0.35066533  0.33421492  0.30468837\n",
      "  0.15137604 -0.08479562]\n",
      "User factors mean: [ 0.03315989  0.03869108  0.03191788  0.02874696  0.04470642  0.04468604\n",
      "  0.03717891  0.02626821  0.03177243  0.02595105  0.03184044  0.03029424\n",
      "  0.03305511  0.03243298  0.02136013  0.04321697  0.03105564  0.02771484\n",
      "  0.02927147  0.03036526  0.02753451  0.02691564  0.03180805  0.0363051\n",
      "  0.01760835  0.03862451  0.02751297  0.03473033  0.03038391  0.02634833\n",
      "  0.03708348  0.02893318  0.03769175  0.03612608  0.03007683  0.02414226\n",
      "  0.02753987  0.0333102   0.02068989  0.03530607  0.02671529  0.02195598\n",
      "  0.02379602  0.04026469  0.03482796  0.04205965  0.02978281  0.03431422\n",
      "  0.03456396  0.03380091]\n",
      "User factors variance: [ 0.0348149   0.04733734  0.04650252  0.03615084  0.05912448  0.0446547\n",
      "  0.04942473  0.03275799  0.03674371  0.03368749  0.03653141  0.02562528\n",
      "  0.0434433   0.03797729  0.02480692  0.06191487  0.03672562  0.03030047\n",
      "  0.03830718  0.03380956  0.03343527  0.03044467  0.03416497  0.04299367\n",
      "  0.02430756  0.04404946  0.03417526  0.03852428  0.03052281  0.02717291\n",
      "  0.03663781  0.03214462  0.02944841  0.0373732   0.02744849  0.02989923\n",
      "  0.03422546  0.03316183  0.02524334  0.0374398   0.03111724  0.02598266\n",
      "  0.02506727  0.04517631  0.03799592  0.04177816  0.03066797  0.03520058\n",
      "  0.04519958  0.03498371]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "\n",
    "movie_matrix = RowMatrix(movie_vectors)\n",
    "user_matrix = RowMatrix(user_vectors)\n",
    "\n",
    "from pyspark.mllib.stat import MultivariateStatisticalSummary\n",
    "desc_movie_matrix = MultivariateStatisticalSummary(movie_matrix.rows)\n",
    "desc_user_matrix = MultivariateStatisticalSummary(user_matrix.rows)\n",
    "\n",
    "print('Movie factors mean:',desc_movie_matrix.mean())\n",
    "print('Movie factors variance:',desc_user_matrix.mean())\n",
    "print('User factors mean:',desc_movie_matrix.variance())\n",
    "print('User factors variance:',desc_user_matrix.variance())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练聚类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前十个样本的预测标签：4,0,2,4,0,1,4,4,4,1\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.clustering import KMeans\n",
    "num_clusters = 5\n",
    "num_iterations = 20\n",
    "movie_cluster_model = KMeans.train(movie_vectors, num_clusters, 100)\n",
    "user_cluster_model = KMeans.train(user_vectors, num_clusters, num_iterations)\n",
    "predictions = movie_cluster_model.predict(movie_vectors)\n",
    "print('前十个样本的预测标签：' + \",\" .join([str(i) for i in predictions.take(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
